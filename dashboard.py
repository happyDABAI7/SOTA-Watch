import streamlit as st
import pandas as pd
import os
from dotenv import load_dotenv
from supabase import create_client, Client
# [æ–°å¢] å¼•å…¥å‘é‡ç”Ÿæˆå™¨
from src.embedder import get_embedding

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="SOTA Watch AI", page_icon="ğŸ§ ", layout="wide")

# 2. èµ„æºåˆå§‹åŒ– (ä½¿ç”¨ cache_resource é¿å…é‡å¤åŠ è½½æ¨¡å‹)
@st.cache_resource
def init_resources():
    load_dotenv()
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_KEY")
    return create_client(url, key)

supabase = init_resources()

# 3. æ•°æ®åŠ è½½é€»è¾‘ (æ™®é€šæ¨¡å¼ vs AI æœç´¢æ¨¡å¼)
def get_data(query_text=None):
    if not query_text:
        # --- æ™®é€šæ¨¡å¼ï¼šç›´æ¥æŸ¥æœ€æ–°çš„ ---
        response = supabase.table("sota_items") \
            .select("*") \
            .order("created_at", desc=True) \
            .limit(50) \
            .execute()
        df = pd.DataFrame(response.data)
        if not df.empty:
            df['similarity'] = 1.0 # é»˜è®¤ç›¸ä¼¼åº¦ä¸º 1
        return df, False
    else:
        # --- AI æ¨¡å¼ï¼šè¯­ä¹‰æœç´¢ ---
        # 1. æŠŠç”¨æˆ·çš„æ–‡å­—å˜æˆå‘é‡
        query_vector = get_embedding(query_text)
        
        # 2. è°ƒç”¨æ•°æ®åº“çš„ RPC å‡½æ•°è¿›è¡Œæœç´¢
        response = supabase.rpc(
            "match_sota_items",
            {
                "query_embedding": query_vector,
                "match_threshold": 0.3, # ç›¸ä¼¼åº¦é˜ˆå€¼
                "match_count": 20
            }
        ).execute()
        
        df = pd.DataFrame(response.data)
        return df, True

# --- UI æ¸²æŸ“ ---

# ä¾§è¾¹æ 
with st.sidebar:
    st.title("ğŸ§  SOTA Brain")
    st.caption("Powered by DeepSeek & Vector Search")
    st.markdown("---")
    
    st.header("ğŸ” Filters")
    min_score = st.slider("Minimum Score", 0, 10, 6)
    
    st.markdown("---")
    if st.button("ğŸ”„ Clear Cache"):
        st.cache_data.clear()
        st.rerun()

# ä¸»ç•Œé¢
st.title("ğŸ“¡ SOTA Watch Radar")

# [æ ¸å¿ƒ] æœç´¢æ¡†
search_query = st.text_input("ğŸ¤– Semantic Search", placeholder="Try: 'video generation' or 'autonomous agents'...")

# è·å–æ•°æ®
with st.spinner("Thinking..."):
    df, is_search_mode = get_data(search_query)

if df.empty:
    st.info("No items found. Try a different query.")
else:
    # è½¬æ¢æ—¶é—´æ ¼å¼
    if 'created_at' in df.columns:
        df['created_at'] = pd.to_datetime(df['created_at'])

    # æœ¬åœ°å†æ¬¡ç­›é€‰ (åˆ†æ•°)
    filtered_df = df[df['score'] >= min_score]

    # ç»Ÿè®¡ä¿¡æ¯
    c1, c2, c3 = st.columns(3)
    c1.metric("Items Found", len(filtered_df))
    if is_search_mode:
        c2.metric("Search Mode", "Semantic ğŸ§ ")
    else:
        c2.metric("Search Mode", "Latest ğŸ•’")

    st.markdown("---")

    # æ¸²æŸ“åˆ—è¡¨
    for index, row in filtered_df.iterrows():
        # åˆ†æ•°é¢œè‰²
        score_color = "green" if row['score'] >= 9 else "orange"
        
        with st.container():
            col_main, col_stats = st.columns([0.85, 0.15])
            
            with col_main:
                prefix = f"[{row.get('tags', 'AI')}]"
                st.subheader(f"{prefix} {row['title']}")
                st.markdown(f"> {row['summary']}")
                st.caption(f"Source: {row['source']} | Date: {row['created_at'].strftime('%Y-%m-%d')}")
                st.markdown(f"[ğŸ”— Original Link]({row['url']})")
            
            with col_stats:
                st.markdown(f"### :{score_color}[{row['score']}]")
                if is_search_mode:
                    # æ˜¾ç¤ºç›¸ä¼¼åº¦åŒ¹é…åˆ†
                    sim = row['similarity'] * 100
                    st.caption(f"Match: {sim:.1f}%")
            
            st.divider()
            