import os
import json
import time
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

# ==========================================
# [DeepSeek å®˜ç½‘ç‰ˆ] 
# ä½¿ç”¨å®˜æ–¹ APIï¼Œç¨³å®šä¸”ä½ å·²ç»å……å€¼äº†ä½™é¢
# ==========================================

API_KEY = os.getenv("DEEPSEEK_API_KEY")

client = None
if API_KEY:
    client = OpenAI(
        api_key=API_KEY,
        # [å…³é”®ä¿®æ”¹] æ”¹å› DeepSeek å®˜æ–¹åœ°å€
        base_url="https://api.deepseek.com"
    )
else:
    print("âš ï¸ Warning: DEEPSEEK_API_KEY not found in env")

def analyze_item_with_llm(item):
    if not client: return None

    prompt = f"""
    ä½ æ˜¯ AI ç§‘æŠ€ç¼–è¾‘ã€‚åˆ†æä»¥ä¸‹é¡¹ç›®ï¼š
    æ ‡é¢˜: {item['title']}
    æè¿°: {item['description']}
    
    ä»»åŠ¡ï¼š
    1. è¯„åˆ† (0-10åˆ†, SOTA/é‡ç£…æ›´æ–°=9-10)ã€‚
    2. ä¸­æ–‡ä¸€å¥è¯æ€»ç»“ã€‚
    3. æ ‡ç­¾ (LLM, Vision, Agent, Tool)ã€‚
    
    è¾“å‡ºçº¯ JSON:
    {{
        "score": <æ•°å­—>,
        "summary": "<ä¸­æ–‡æ€»ç»“>",
        "tag": "<æ ‡ç­¾>"
    }}
    """
    try:
        # [å…³é”®ä¿®æ”¹] æ”¹å› DeepSeek å®˜æ–¹æ¨¡å‹åç§°
        model_name = "deepseek-chat" 
        
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "You output JSON only."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.1,
            max_tokens=512
        )
        
        content = response.choices[0].message.content.strip()
        
        if content.startswith("```"):
            content = content.split("\n", 1)[1].rsplit("\n", 1)[0]
            
        return json.loads(content)

    except Exception as e:
        print(f"   âŒ API Error: {e}")
        return None

def process_data(raw_items: list) -> str:
    print(f"\nğŸ§  [Processor] Starting AI analysis on {len(raw_items)} items...")
    
    if not raw_items: return "No data."
        
    sota_items = []
    # äº‘ç«¯è¿è¡Œé€Ÿåº¦å¿«ï¼Œå¤„ç†å‰ 10 æ¡
    # test_batch = raw_items[:10] 
    items_to_process = raw_items 
    
    print(f"\nğŸ§  [Processor] Starting AI analysis on {len(items_to_process)} items...")

    sota_items = []
    
    for i, item in enumerate(test_batch):
        print(f"   ({i+1}/{len(test_batch)}) Analyzing: {item['title']} ...", end="")
        
        analysis = analyze_item_with_llm(item)
        
        if analysis:
            print(f" Score: {analysis.get('score')}")
            if analysis.get('score', 0) >= 6:
                item.update(analysis)
                sota_items.append(item)
        else:
            print(" Skipped (Error)")
        
        time.sleep(0.5)

    if not sota_items:
        return "ğŸ”• No high-score updates found."

    report = f"# ğŸš¨ SOTA Watch Daily\n\n"
    for item in sota_items:
        report += f"### [{item.get('tag','AI')}] {item['title']}\n"
        report += f"**å¾—åˆ†:** {item.get('score',0)}/10\n"
        report += f"> ğŸ’¡ {item.get('summary', 'æš‚æ— ')}\n\n"
        report += f"ğŸ”— [Link]({item['url']})\n"
        report += "---\n"
        
    return report
