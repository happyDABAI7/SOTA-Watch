import os
import json
import time
from dotenv import load_dotenv
from openai import OpenAI
# [æ–°å¢] å¼•å…¥çˆ¬è™«
from src.crawler import scrape_content

load_dotenv()

API_KEY = os.getenv("DEEPSEEK_API_KEY")

client = None
if API_KEY:
    client = OpenAI(
        api_key=API_KEY,
        base_url="https://api.deepseek.com"
    )
else:
    print("âš ï¸ Warning: DEEPSEEK_API_KEY not found")

def analyze_item_deeply(item):
    if not client: return None

    # 1. [æ·±åº¦é˜…è¯»] çˆ¬å–å…¨æ–‡
    full_content = scrape_content(item['url'])
    
    # å¦‚æœçˆ¬å–å¤±è´¥ï¼Œå›é€€åˆ°ä½¿ç”¨åŸæ¥çš„æè¿°
    context = full_content if full_content else item['description']

    # 2. [V4.0 ç»ˆæ Prompt]
    prompt = f"""
    ä½ æ˜¯ SOTA Watch çš„é¦–å¸­æŠ€æœ¯å®˜ã€‚è¯·åŸºäºä»¥ä¸‹ã€é¡¹ç›®è¯¦æƒ…ã€‘ï¼Œä¸¥æ ¼è¯„ä¼°å…¶æŠ€æœ¯ä»·å€¼ã€‚
    
    æ ‡é¢˜: {item['title']}
    é“¾æ¥: {item['url']}
    åŸå§‹æè¿°: {item['description']}
    
    ã€é¡¹ç›®è¯¦æƒ… (Markdown)ã€‘:
    {context[:4000]} ...
    
    ã€ä»»åŠ¡ã€‘:
    1. **åˆ¤å®šå™ªéŸ³**:
       - å¦‚æœæ˜¯ è¯¾ç¨‹(Course)ã€æ•™ç¨‹(Tutorial)ã€é¢è¯•é¢˜ã€èµ„æºåˆ—è¡¨(Awesome List)ã€è¥é”€è½¯æ–‡ -> æ ‡è®°ä¸º is_noise: trueã€‚
       - å¦‚æœæ˜¯ çœŸå®çš„ä»£ç åº“ã€æ¨¡å‹æƒé‡ã€æŠ€æœ¯è®ºæ–‡ -> æ ‡è®°ä¸º is_noise: falseã€‚
    
    2. **æŠ€æœ¯è¯„åˆ† (0-10)**:
       - 10åˆ†: è¡Œä¸šé‡Œç¨‹ç¢‘ (å¦‚ DeepSeek-V3, Llama 3, Sora)ã€‚
       - 8-9åˆ†: é«˜è´¨é‡ SOTA å·¥å…·/æ¡†æ¶ (å¦‚ LangChain æ›´æ–°, æ–°çš„ Agent æ¡†æ¶)ã€‚
       - 6-7åˆ†: æ™®é€šçš„ Demo æˆ– è®ºæ–‡å®ç°ã€‚
       - <6åˆ†: ç¼ºä¹åˆ›æ–°çš„ Wrapper æˆ– ç®€å•è„šæœ¬ã€‚

    3. **æ·±åº¦æ€»ç»“**: ç”¨ä¸­æ–‡ï¼ŒåŸºäºã€é¡¹ç›®è¯¦æƒ…ã€‘å†™ 50-80 å­—çš„ç¡¬æ ¸æŠ€æœ¯æ‘˜è¦ã€‚
    
    4. **æ ‡ç­¾**: (LLM, Vision, Agent, Framework, Hardware, Audio)ã€‚

    è¾“å‡ºçº¯ JSON:
    {{
        "is_noise": <bool>,
        "score": <int>,
        "summary": "<string>",
        "tag": "<string>"
    }}
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "You output JSON only."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.1,
            max_tokens=1024
        )
        content = response.choices[0].message.content.strip()
        if content.startswith("```"):
            content = content.split("\n", 1)[1].rsplit("\n", 1)[0]
        return json.loads(content)

    except Exception as e:
        print(f"   âŒ Analysis Error: {e}")
        return None

def process_data(raw_items: list) -> str:
    # 1. [ç²—ç­›] å…³é”®è¯è¿‡æ»¤ï¼Œçœé’±çœæ—¶é—´
    candidates = []
    # è¿™äº›è¯å‡ºç°åœ¨æ ‡é¢˜é‡Œï¼Œç›´æ¥æªæ¯™ï¼Œä¸éœ€è¦ AI çœ‹
    noise_keywords = ["course", "tutorial", "learn ", "101", "roadmap", "cheatsheet", "interview", "awesome"]
    
    for item in raw_items:
        title_lower = item['title'].lower()
        if any(k in title_lower for k in noise_keywords):
            print(f"   ğŸ—‘ï¸ [Pre-Filter] Dropped noise: {item['title']}")
            continue
        candidates.append(item)

    print(f"\nğŸ§  [Processor] Deep analyzing {len(candidates)} items (Filtered from {len(raw_items)})...")
    
    if not candidates: return "No qualified data."
    
    sota_items = []
    
    # å…¨é‡è·‘
    for i, item in enumerate(candidates):
        print(f"   ({i+1}/{len(candidates)}) Deep Reading: {item['title']} ...")
        
        analysis = analyze_item_deeply(item)
        
        if analysis:
            score = analysis.get('score', 0)
            is_noise = analysis.get('is_noise', False)
            print(f"      -> Score: {score} | Noise: {is_noise}")
            
            # [ä¸¥é€‰æ ‡å‡†] éå™ªéŸ³ ä¸” åˆ†æ•° >= 7
            if not is_noise and score >= 7:
                item.update(analysis)
                sota_items.append(item)
        else:
            print("      -> Skipped (Error)")
        
        # çˆ¬è™«éœ€è¦ç¤¼è²Œï¼Œé—´éš” 1.5 ç§’
        time.sleep(1.5)

    if not sota_items:
        return "ğŸ”• No SOTA updates found (Strict filtering)."

    report = f"# ğŸš¨ SOTA Watch Daily (Deep Dive)\n\n"
    for item in sota_items:
        report += f"### [{item.get('tag','AI')}] {item['title']}\n"
        report += f"**å¾—åˆ†:** {item.get('score',0)}/10\n"
        report += f"> ğŸ“ {item.get('summary', 'æš‚æ— ')}\n\n"
        report += f"ğŸ”— [æŸ¥çœ‹è¯¦æƒ…]({item['url']})\n"
        report += "---\n"
        
    return report