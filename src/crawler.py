import requests
import time
import logging

logger = logging.getLogger(__name__)

def scrape_content(url: str) -> str:
    """
    ä½¿ç”¨ Jina Reader å°†ä»»æ„ URL è½¬æ¢ä¸ºå¯¹ LLM å‹å¥½çš„ Markdownã€‚
    åŸç†ï¼šåœ¨ URL å‰åŠ  https://r.jina.ai/
    """
    # æ„é€  Jina Reader API åœ°å€
    jina_url = f"https://r.jina.ai/{url}"
    
    headers = {
        "User-Agent": "SotaWatchBot/4.0",
        # å‘Šè¯‰ Jina æˆ‘ä»¬ä¸éœ€è¦å›¾ç‰‡ï¼Œåªè¦çº¯æ–‡æœ¬ï¼ŒèŠ‚çœ token
        "X-Retain-Images": "none" 
    }
    
    # print(f"   ğŸ•·ï¸ [Crawler] Deep reading: {url} ...")
    
    try:
        # è®¾ç½® 20ç§’è¶…æ—¶ï¼Œé˜²æ­¢å¡æ­»
        response = requests.get(jina_url, headers=headers, timeout=20)
        
        if response.status_code == 200:
            content = response.text
            # æˆªæ–­ç­–ç•¥ï¼š
            # DeepSeek V3 çª—å£å¾ˆå¤§ï¼Œä½†ä¸ºäº†å“åº”é€Ÿåº¦ï¼Œæˆ‘ä»¬å–å‰ 6000 å­—ç¬¦
            # è¿™é€šå¸¸åŒ…å«äº† README çš„ Header, Features, å’Œ Quick Start
            return content[:6000]
        else:
            logger.warning(f"Crawler failed ({response.status_code}): {url}")
            return ""
            
    except Exception as e:
        logger.error(f"Crawler Exception: {e}")
        return ""

if __name__ == "__main__":
    # æµ‹è¯•ä¸€ä¸‹
    print("Testing crawler...")
    text = scrape_content("https://github.com/deepseek-ai/DeepSeek-V3")
    print(f"Content Length: {len(text)}")
    print(text[:500])
    